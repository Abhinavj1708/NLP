{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86741afc",
   "metadata": {},
   "source": [
    "## Details:13-01-2023 - 20BCE2624"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24687a51",
   "metadata": {},
   "source": [
    "## Topic: Stemming Of Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fb1ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ec8e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/files/98/98-0.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e42814",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = request.urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f06fa02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = response.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de32ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcbb27a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'eBook', 'of', 'A', 'Tale', 'of', 'Two', 'Cities', ',', 'by', 'Charles', 'Dickens', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.', 'You', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org', '.', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', ',', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'eBook', '.', 'Title', ':', 'A', 'Tale', 'of', 'Two', 'Cities', 'A', 'Story', 'of', 'the', 'French', 'Revolution', 'Author', ':', 'Charles', 'Dickens', 'Release', 'Date', ':', 'January', ',', '1994', '[', 'eBook', '#', '98', ']', '[', 'Most', 'recently', 'updated', ':', 'December', '20', ',', '2020', ']', 'Language', ':', 'English', 'Character', 'set', 'encoding', ':', 'UTF-8', 'Produced', 'by', ':', 'Judith', 'Boss', 'and', 'David', 'Widger', '*', '*', '*', 'START', 'OF', 'THE', 'PROJECT', 'GUTENBERG', 'EBOOK', 'A', 'TALE', 'OF', 'TWO', 'CITIES', '*', '*', '*', 'A', 'TALE', 'OF', 'TWO', 'CITIES', 'A', 'STORY', 'OF', 'THE', 'FRENCH', 'REVOLUTION', 'By', 'Charles', 'Dickens', 'CONTENTS', 'Book', 'the', 'First', '--', 'Recalled', 'to', 'Life', 'CHAPTER', 'I', 'The', 'Period', 'CHAPTER', 'II']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7471d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See to it \n",
    "# BeautifulSoup\n",
    "# Preprocessing - RE to clean any html tags\n",
    "# POS Tagging\n",
    "# !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeb64747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happi\n",
      "joyou\n",
      "cacti\n",
      "sing\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "print(porter.stem('happiness'))\n",
    "print(porter.stem('joyous'))\n",
    "print(porter.stem('cacti'))\n",
    "print(porter.stem('singing'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc666ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy\n",
      "joy\n",
      "cact\n",
      "sing\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lanc = LancasterStemmer()\n",
    "print(lanc.stem('happiness'))\n",
    "print(lanc.stem('joyous'))\n",
    "print(lanc.stem('cacti'))\n",
    "print(lanc.stem('singing'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79ff9051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk\n",
      "sing\n",
      "r\n",
      "cacti\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "regex = RegexpStemmer('ing')\n",
    "print(regex.stem('walking'))\n",
    "regex = RegexpStemmer('ing$')  # just removes -ing once\n",
    "print(regex.stem('singing'))\n",
    "print(regex.stem('ring')) # SHOULDN'T HAVE STEMMING\n",
    "print(regex.stem('cacti'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "208a30b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mang\n",
      "messieur\n",
      "robust\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snow = SnowballStemmer(language = 'french')\n",
    "print(snow.stem('manges')) # WRONG (Should be mange)\n",
    "print(snow.stem('messieurs'))\n",
    "print(snow.stem('robuste'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c3ce82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SnowballStemmer in module nltk.stem.snowball:\n",
      "\n",
      "class SnowballStemmer(nltk.stem.api.StemmerI)\n",
      " |  SnowballStemmer(language, ignore_stopwords=False)\n",
      " |  \n",
      " |  Snowball Stemmer\n",
      " |  \n",
      " |  The following languages are supported:\n",
      " |  Arabic, Danish, Dutch, English, Finnish, French, German,\n",
      " |  Hungarian, Italian, Norwegian, Portuguese, Romanian, Russian,\n",
      " |  Spanish and Swedish.\n",
      " |  \n",
      " |  The algorithm for English is documented here:\n",
      " |  \n",
      " |      Porter, M. \"An algorithm for suffix stripping.\"\n",
      " |      Program 14.3 (1980): 130-137.\n",
      " |  \n",
      " |  The algorithms have been developed by Martin Porter.\n",
      " |  These stemmers are called Snowball, because Porter created\n",
      " |  a programming language with this name for creating\n",
      " |  new stemming algorithms. There is more information available\n",
      " |  at http://snowball.tartarus.org/\n",
      " |  \n",
      " |  The stemmer is invoked as shown below:\n",
      " |  \n",
      " |  >>> from nltk.stem import SnowballStemmer\n",
      " |  >>> print(\" \".join(SnowballStemmer.languages)) # See which languages are supported\n",
      " |  arabic danish dutch english finnish french german hungarian\n",
      " |  italian norwegian porter portuguese romanian russian\n",
      " |  spanish swedish\n",
      " |  >>> stemmer = SnowballStemmer(\"german\") # Choose a language\n",
      " |  >>> stemmer.stem(\"Autobahnen\") # Stem a word\n",
      " |  'autobahn'\n",
      " |  \n",
      " |  Invoking the stemmers that way is useful if you do not know the\n",
      " |  language to be stemmed at runtime. Alternatively, if you already know\n",
      " |  the language, then you can invoke the language specific stemmer directly:\n",
      " |  \n",
      " |  >>> from nltk.stem.snowball import GermanStemmer\n",
      " |  >>> stemmer = GermanStemmer()\n",
      " |  >>> stemmer.stem(\"Autobahnen\")\n",
      " |  'autobahn'\n",
      " |  \n",
      " |  :param language: The language whose subclass is instantiated.\n",
      " |  :type language: str or unicode\n",
      " |  :param ignore_stopwords: If set to True, stopwords are\n",
      " |                           not stemmed and returned unchanged.\n",
      " |                           Set to False by default.\n",
      " |  :type ignore_stopwords: bool\n",
      " |  :raise ValueError: If there is no stemmer for the specified\n",
      " |                         language, a ValueError is raised.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SnowballStemmer\n",
      " |      nltk.stem.api.StemmerI\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, language, ignore_stopwords=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  stem(self, token)\n",
      " |      Strip affixes from the token and return the stem.\n",
      " |      \n",
      " |      :param token: The token that should be stemmed.\n",
      " |      :type token: str\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  languages = ('arabic', 'danish', 'dutch', 'english', 'finnish', 'frenc...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from nltk.stem.api.StemmerI:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SnowballStemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca46a6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffthe', 'project', 'gutenberg', 'ebook', 'of', 'a', 'tale', 'of', 'two', 'citi', ',', 'by', 'charl', 'dicken', 'thi', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyon', 'anywher', 'in', 'the', 'unit', 'state', 'and', 'most', 'other', 'part', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrict', 'whatsoev', '.', 'you', 'may', 'copi', 'it', ',', 'give', 'it', 'away', 'or', 're-us', 'it', 'under', 'the', 'term', 'of', 'the', 'project', 'gutenberg', 'licens', 'includ', 'with', 'thi', 'ebook', 'or', 'onlin', 'at', 'www.gutenberg.org', '.', 'if', 'you', 'are', 'not', 'locat', 'in', 'the', 'unit', 'state', ',', 'you', 'will', 'have', 'to', 'check', 'the', 'law', 'of', 'the', 'countri', 'where', 'you', 'are', 'locat', 'befor', 'use', 'thi', 'ebook', '.', 'titl', ':', 'a', 'tale', 'of', 'two', 'citi', 'a', 'stori', 'of', 'the', 'french', 'revolut', 'author', ':', 'charl', 'dicken', 'releas', 'date', ':', 'januari', ',', '1994', '[', 'ebook', '#', '98', ']', '[', 'most', 'recent', 'updat', ':', 'decemb', '20', ',', '2020', ']', 'languag', ':', 'english', 'charact', 'set', 'encod', ':', 'utf-8', 'produc', 'by', ':', 'judith', 'boss', 'and', 'david', 'widger', '*', '*', '*', 'start', 'of', 'the', 'project', 'gutenberg', 'ebook', 'a', 'tale', 'of', 'two', 'citi', '*', '*', '*', 'a', 'tale', 'of', 'two', 'citi', 'a', 'stori', 'of', 'the', 'french', 'revolut', 'by', 'charl', 'dicken', 'content', 'book', 'the', 'first', '--', 'recal', 'to', 'life', 'chapter', 'i', 'the', 'period', 'chapter', 'ii']\n"
     ]
    }
   ],
   "source": [
    "stemmed1 = [porter.stem(i) for i in tokens]\n",
    "print(stemmed1[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97c3407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "para = \"\"\"It was the best of times, it was the worst of times, it was the age of\n",
    "wisdom, it was the age of foolishness, it was the epoch of belief, it\n",
    "was the epoch of incredulity, it was the season of Light, it was the\n",
    "season of Darkness, it was the spring of hope, it was the winter of\n",
    "despair, we had everything before us, we had nothing before us, we were\n",
    "all going direct to Heaven, we were all going direct the other way--in\n",
    "short, the period was so far like the present period, that some of its\n",
    "noisiest authorities insisted on its being received, for good or for\n",
    "evil, in the superlative degree of comparison only.\n",
    "\n",
    "There were a king with a large jaw and a queen with a plain face, on the\n",
    "throne of England; there were a king with a large jaw and a queen with\n",
    "a fair face, on the throne of France. In both countries it was clearer\n",
    "than crystal to the lords of the State preserves of loaves and fishes,\n",
    "that things in general were settled for ever.\n",
    "\"\"\"\n",
    "stemmed2 = [porter.stem(i) for i in para.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7aaf8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'wa', 'the', 'best', 'of', 'times,', 'it', 'wa', 'the', 'worst', 'of', 'times,', 'it', 'wa', 'the', 'age', 'of\\nwisdom,', 'it', 'wa', 'the', 'age', 'of', 'foolishness,', 'it', 'wa', 'the', 'epoch', 'of', 'belief,', 'it\\nwa', 'the', 'epoch', 'of', 'incredulity,', 'it', 'wa', 'the', 'season', 'of', 'light,', 'it', 'wa', 'the\\nseason', 'of', 'darkness,', 'it', 'wa', 'the', 'spring', 'of', 'hope,', 'it', 'wa', 'the', 'winter', 'of\\ndespair,', 'we', 'had', 'everyth', 'befor', 'us,', 'we', 'had', 'noth', 'befor', 'us,', 'we', 'were\\nal', 'go', 'direct', 'to', 'heaven,', 'we', 'were', 'all', 'go', 'direct', 'the', 'other', 'way--in\\nshort,', 'the', 'period', 'wa', 'so', 'far', 'like', 'the', 'present', 'period,', 'that', 'some', 'of', 'its\\nnoisiest', 'author', 'insist', 'on', 'it', 'be', 'received,', 'for', 'good', 'or', 'for\\nevil,', 'in', 'the', 'superl', 'degre', 'of', 'comparison', 'only.\\n\\nther', 'were', 'a', 'king', 'with', 'a', 'larg', 'jaw', 'and', 'a', 'queen', 'with', 'a', 'plain', 'face,', 'on', 'the\\nthron', 'of', 'england;', 'there', 'were', 'a', 'king', 'with', 'a', 'larg', 'jaw', 'and', 'a', 'queen', 'with\\na', 'fair', 'face,', 'on', 'the', 'throne', 'of', 'france.', 'in', 'both', 'countri', 'it', 'wa', 'clearer\\nthan', 'crystal', 'to', 'the', 'lord', 'of', 'the', 'state', 'preserv', 'of', 'loav', 'and', 'fishes,\\nthat', 'thing', 'in', 'gener', 'were', 'settl', 'for', 'ever.\\n']\n"
     ]
    }
   ],
   "source": [
    "print(stemmed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "719c6cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cactus\n",
      "mouse\n",
      "monsieur\n",
      "chicken\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "print(lemma.lemmatize(\"cacti\"))\n",
    "print(lemma.lemmatize(\"mice\"))\n",
    "print(lemma.lemmatize(\"messieurs\"))\n",
    "print(lemma.lemmatize(\"chicken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d03c236b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "# lemmatizer with 2nd argument as POS\n",
    "print(lemma.lemmatize(\"am\", pos = 'v')) # Verb\n",
    "print(lemma.lemmatize(\"better\", pos = 'a')) # Adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e5058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
